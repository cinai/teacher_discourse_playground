{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"..\\data\\images\\teaching_physics.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing transcriptions of physics classroom sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to <a href=Introduction.ipynb>this</a> notebook!\n",
    "\n",
    "The aim of this document is to summarize the different approaches used to analyze the transcriptions of physics clasroom sessions. We recorded and transcribed classroom sessions using the <a href=https://smartspeech.azurewebsites.net>SmartSpeech app</a>. We used the transcriptions of clasroom sessions to:\n",
    "- understand the relation among sessions (similarity by topic or by grade)\n",
    "- analyze the use of specific words, combination of words and concept relations\n",
    "- analyze the temporal dimension of the appearence of words during the clasroom sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consist in 56 physic clasroom sessions by Heber, brother of Obed. Each session is saved in a .txt file (you can find them in the <a href=http://localhost:8888/tree/Documents/clusters%20ciae/data>data</a> folder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering all the sessions, there are:\n",
    "\n",
    "- Total number of words: 277,789\n",
    "\n",
    "- Size of set of words: 14,208"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the number of session by grade and topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CATALINA ESPINOZA\\AppData\\Local\\conda\\conda\\envs\\env27\\lib\\site-packages\\pydub\\utils.py:165: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from packages.text_clustering import text_preprocessing as tp\n",
    "import os\n",
    "root_path = 'C:\\Users\\CATALINA ESPINOZA\\Documents\\clusters ciae'\n",
    "data_path = os.path.join(root_path,'data')\n",
    "output_path = os.path.join(root_path,'output')\n",
    "by_grade_and_content = os.path.join(data_path,'textos_ulloa_by_grade_content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuarto/\n",
      "    aplicaciones campo eléctrico(1)\n",
      "    campo magnético y transformadores(1)\n",
      "    condensadores y magnetismo(1)\n",
      "    electivo psu (luz)(1)\n",
      "    electrodinamica(2)\n",
      "    flujo magnético(1)\n",
      "    fuerza electrostática(1)\n",
      "    fuerza y campo eléctrico(1)\n",
      "    psu física (luz)(1)\n",
      "octavo/\n",
      "    centrales eléctricas(1)\n",
      "    circuitos(1)\n",
      "    energía eléctrica(2)\n",
      "    ley de ohm(1)\n",
      "    potencia y energía eléctrica(2)\n",
      "    voltaje(1)\n",
      "primero/\n",
      "    fenómenos de la luz(3)\n",
      "    fenómenos del sonido(3)\n",
      "    fenómenos ondulatorios(1)\n",
      "    interferencia de la luz(1)\n",
      "    luz(1)\n",
      "    sonido(1)\n",
      "    óptica de la luz(2)\n",
      "segundo/\n",
      "    aplicaciones del mrua y mrur(2)\n",
      "    dinámica(1)\n",
      "    fuerza de roce(1)\n",
      "    leyes de newton(2)\n",
      "    movimiento rectilineo uniforme(1)\n",
      "    mrua(1)\n",
      "    mrua y mrur(3)\n",
      "    torque(1)\n",
      "    torque y palancas(2)\n",
      "septimo/\n",
      "    el clima(1)\n",
      "    elementos del clima(1)\n",
      "    factores del clima(2)\n",
      "    factores geográficos(2)\n",
      "    presión(2)\n",
      "tercero/\n",
      "    fluidos(2)\n",
      "    principio de pascal(1)\n",
      "    torque(1)\n"
     ]
    }
   ],
   "source": [
    "reload(tp)\n",
    "tp.list_files(by_grade_and_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a scatter plot of the length of the sessions (minutes) by the number of words of the sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"..\\data\\images\\descarga.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a wordcloud with the most frequent words used by Heber during the lessons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sacar imagen ahora (1 pom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clasroom session representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we describe the different approaches used to represent the clasroom sessions transcriptions. As we are working with transcriptions, we refer to the clasroom sessions as documents. To exemplify each approach, we are going to use the following auxiliar document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auxiliar_document = ['This document is just an example','It is not a transcription of a session','Remember it is just an example']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Warning: the document above is just an example, it is not a transcription of a session</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Real warning: each element of the list is representing a line of the document. A line correspond to 5 seconds of the lesson in the real documents.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  General preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the approaches presented in the following subsections work with preprocessed documents. The preprocessing tasks are described in detail in the corresponding notebooks. Here are some typical preprocessing tasks, that prepare the auxiliar document that later will help us to exemplify the different approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# work with words in lower case\n",
    "auxiliar_document = map(lambda x: x.lower(),auxiliar_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'document', 'is', 'just', 'an', 'example', 'it', 'is', 'not', 'a', 'transcription', 'of', 'a', 'session', 'remember', 'it', 'is', 'just', 'an', 'example']\n"
     ]
    }
   ],
   "source": [
    "# work with separated words (not lines)\n",
    "split_words = [j for i in auxiliar_document for j in i.split()]\n",
    "print split_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'an', 'document', 'example', 'is', 'it', 'just', 'not', 'of', 'remember', 'session', 'this', 'transcription']\n"
     ]
    }
   ],
   "source": [
    "# work with the set of words (no repetition)\n",
    "set_of_words = sorted(set(split_words))\n",
    "print set_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"Preprocessing\">Here</a> are the notebooks with some general preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each document is transformed into a vector where each component represents the importance in the document of a specific word. The importance of a word can be measured, for example, by the frequency of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_frequency = []\n",
    "for i in set_of_words:\n",
    "    words_frequency.append(split_words.count(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the vector with the frequency of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 1, 2, 3, 2, 2, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# it looks like a list, but it is a vector\n",
    "print words_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is each word with its corresponding frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 2)\n",
      "('an', 2)\n",
      "('document', 1)\n",
      "('example', 2)\n",
      "('is', 3)\n",
      "('it', 2)\n",
      "('just', 2)\n",
      "('not', 1)\n",
      "('of', 1)\n",
      "('remember', 1)\n",
      "('session', 1)\n",
      "('this', 1)\n",
      "('transcription', 1)\n"
     ]
    }
   ],
   "source": [
    "for i in zip(set_of_words,words_frequency):\n",
    "    print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"Words\">Here</a> are the notebooks with the analysis using word vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Pair of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each document is transformed into a matrix that holds the frequency in which a pair of words is enunciated together.\n",
    "\n",
    "First, we select an interesting group of words. For example, the complete set of words: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'an',\n",
       " 'document',\n",
       " 'example',\n",
       " 'is',\n",
       " 'it',\n",
       " 'just',\n",
       " 'not',\n",
       " 'of',\n",
       " 'remember',\n",
       " 'session',\n",
       " 'this',\n",
       " 'transcription']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we build a matrix $connective\\_matrix$, size $n \\times n$, where $n$ is the length of the set of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "connective_matrix = np.zeros((len(set_of_words),len(set_of_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each cell of $connective\\_matrix$ holds the frequency in which a word $w_i$ is enunciate before a word $w_j$ (in the same line), denoting a temporal relation between $w_i\\rightarrow w_j$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for w in set_of_words:\n",
    "    matrix_i = set_of_words.index(w)\n",
    "    for line in auxiliar_document:\n",
    "        line_words = line.split()\n",
    "        for w_i in range(len(line_words)):\n",
    "            if line_words[w_i] == w:\n",
    "                for w_j in range(len(line_words)):\n",
    "                    if w_i < w_j:\n",
    "                        matrix_j =set_of_words.index(line_words[w_j])\n",
    "                        if matrix_i != matrix_j:\n",
    "                            connective_matrix[matrix_i,matrix_j] += 1\n",
    "        connective_matrix[matrix_i,matrix_i] += line_words.count(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this is how it looks a pair of words representation of a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>an</th>\n",
       "      <th>document</th>\n",
       "      <th>example</th>\n",
       "      <th>is</th>\n",
       "      <th>it</th>\n",
       "      <th>just</th>\n",
       "      <th>not</th>\n",
       "      <th>of</th>\n",
       "      <th>remember</th>\n",
       "      <th>session</th>\n",
       "      <th>this</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>example</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remember</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transcription</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 a   an  document  example   is   it  just  not   of  \\\n",
       "a              2.0  0.0       0.0      0.0  0.0  0.0   0.0  0.0  1.0   \n",
       "an             0.0  2.0       0.0      2.0  0.0  0.0   0.0  0.0  0.0   \n",
       "document       0.0  1.0       1.0      1.0  1.0  0.0   1.0  0.0  0.0   \n",
       "example        0.0  0.0       0.0      2.0  0.0  0.0   0.0  0.0  0.0   \n",
       "is             2.0  2.0       0.0      2.0  3.0  0.0   2.0  1.0  1.0   \n",
       "it             2.0  1.0       0.0      1.0  2.0  2.0   1.0  1.0  1.0   \n",
       "just           0.0  2.0       0.0      2.0  0.0  0.0   2.0  0.0  0.0   \n",
       "not            2.0  0.0       0.0      0.0  0.0  0.0   0.0  1.0  1.0   \n",
       "of             1.0  0.0       0.0      0.0  0.0  0.0   0.0  0.0  1.0   \n",
       "remember       0.0  1.0       0.0      1.0  1.0  1.0   1.0  0.0  0.0   \n",
       "session        0.0  0.0       0.0      0.0  0.0  0.0   0.0  0.0  0.0   \n",
       "this           0.0  1.0       1.0      1.0  1.0  0.0   1.0  0.0  0.0   \n",
       "transcription  1.0  0.0       0.0      0.0  0.0  0.0   0.0  0.0  1.0   \n",
       "\n",
       "               remember  session  this  transcription  \n",
       "a                   0.0      2.0   0.0            1.0  \n",
       "an                  0.0      0.0   0.0            0.0  \n",
       "document            0.0      0.0   0.0            0.0  \n",
       "example             0.0      0.0   0.0            0.0  \n",
       "is                  0.0      1.0   0.0            1.0  \n",
       "it                  0.0      1.0   0.0            1.0  \n",
       "just                0.0      0.0   0.0            0.0  \n",
       "not                 0.0      1.0   0.0            1.0  \n",
       "of                  0.0      1.0   0.0            0.0  \n",
       "remember            1.0      0.0   0.0            0.0  \n",
       "session             0.0      1.0   0.0            0.0  \n",
       "this                0.0      0.0   1.0            0.0  \n",
       "transcription       0.0      1.0   0.0            1.0  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame(connective_matrix)\n",
    "df.columns = set_of_words\n",
    "df.index = set_of_words\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this document is just an example',\n",
       " 'it is not a transcription of a session',\n",
       " 'remember it is just an example']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is the document to check the relation between topics\n",
    "auxiliar_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.as_matrix().diagonal() == np.array(words_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"Pair_of_words\">Here</a> are the notebooks with the analysis using pair of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Pair of topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the representation by pair of words (section 3.2), pair of topics representation uses matrices that holds the connection between topics in the documents. A topic is a group of words that are related with each other. A word can belong to different topics. Each word in a topic has a score of its belonging.\n",
    "\n",
    "For example, here are two topics for the auxiliar document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# topic_1 contains words regarding the session\n",
    "topic_1 = ['document','session','transcription']\n",
    "# topic_2 contains words used to teach\n",
    "topic_2 = ['example','remember']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this document is just an example',\n",
       " 'it is not a transcription of a session',\n",
       " 'remember it is just an example']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auxiliar_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Note: for simplicity we assume every word has a score equal to 1, and each word belongs to different classes</i>\n",
    "\n",
    "Now, we build the pair of topics matrix counting the times that each topic is related to the other across the document. This time, the $connective\\_matrix$ size is $n \\times n$, where $n$ is the number of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics = [topic_1,topic_2]\n",
    "connective_matrix = np.zeros((len(topics),len(topics)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each word in each topic, it is calculated the relation of that word with the words of other topics. Besides, the diagonal of the $connective\\_matrix$ represent the sum of the frequencies of the topic's words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for topic_index in range(len(topics)):\n",
    "    for w in topics[topic_index]:\n",
    "        for line in auxiliar_document:\n",
    "            line_words = line.split()\n",
    "            if w in line_words:\n",
    "                w_i = line_words.index(w)\n",
    "                for w_j in range(len(line_words)):\n",
    "                    if w_i < w_j and line_words[w_j] != w:\n",
    "                        for other_topic_index in range(len(topics)):\n",
    "                            if other_topic_index != topic_index:\n",
    "                                if line_words[w_j] in topics[other_topic_index]:\n",
    "                                    connective_matrix[topic_index,other_topic_index] += 1\n",
    "                connective_matrix[topic_index,topic_index] += line_words.count(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>teaching</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>session</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teaching</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session  teaching\n",
       "session       3.0       1.0\n",
       "teaching      0.0       3.0"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(connective_matrix)\n",
    "df.columns = ['session','teaching']\n",
    "df.index = ['session','teaching']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this document is just an example',\n",
       " 'it is not a transcription of a session',\n",
       " 'remember it is just an example']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is the document to check the relation between topics\n",
    "auxiliar_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"Pair_of_topics\">Here</a> are the notebooks with the analysis using pair of topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Other analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Epistemic networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env27]",
   "language": "python",
   "name": "conda-env-env27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
